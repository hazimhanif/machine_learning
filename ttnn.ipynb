{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truth Table Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import package\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define data\n",
    "\n",
    "x = [[False,False],[False,True],[True,False],[True,True]]\n",
    "y = [False,True,True,False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0. 1.]\n",
      "   [1. 0.]]\n",
      "\n",
      "  [[0. 1.]\n",
      "   [1. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 1.]\n",
      "   [1. 0.]]\n",
      "\n",
      "  [[1. 0.]\n",
      "   [0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 0.]\n",
      "   [0. 1.]]\n",
      "\n",
      "  [[0. 1.]\n",
      "   [1. 0.]]]\n",
      "\n",
      "\n",
      " [[[1. 0.]\n",
      "   [0. 1.]]\n",
      "\n",
      "  [[1. 0.]\n",
      "   [0. 1.]]]] \n",
      "\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "## OHE the data\n",
    "\n",
    "x = tf.keras.utils.to_categorical(x, num_classes=2)\n",
    "print(x,'\\n')\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define model\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.RNN(10))\n",
    "model.add(tf.keras.layers.Dense(4, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.0001)\n",
    "\n",
    "## Compile model with metrics\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "## Train the model\n",
    "hist = model.fit(x,y, epochs=500, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:\n",
      " 0.6934748888015747\n",
      "Accuracy:\n",
      " 0.5\n",
      "\n",
      "Prediction:\n",
      " [[[0.48190063]\n",
      "  [0.48190063]]\n",
      "\n",
      " [[0.48190063]\n",
      "  [0.5003518 ]]\n",
      "\n",
      " [[0.5003518 ]\n",
      "  [0.48190063]]\n",
      "\n",
      " [[0.5003518 ]\n",
      "  [0.5003518 ]]]\n",
      "\n",
      "Classes:\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss:\\n\", hist.history['loss'][-1])\n",
    "print(\"Accuracy:\\n\", hist.history['accuracy'][-1])\n",
    "print(\"\\nPrediction:\\n\",model.predict(x))\n",
    "print(\"\\nClasses:\\n\",model.predict_classes(x)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "T, F = 1.00001, -1.00001\n",
    "bias = 1.00001\n",
    "train_in = [\n",
    "    [T, T, bias],\n",
    "    [T, F, bias],\n",
    "    [F, T, bias],\n",
    "    [F, F, bias],\n",
    "]\n",
    "train_out = [\n",
    "    [T],\n",
    "    [F],\n",
    "    [F],\n",
    "    [F],\n",
    "]\n",
    "w = tf.Variable(tf.random.normal([3, 1]))\n",
    "# step(x) = { 1 if x > 0; -1 otherwise }\n",
    "def step(x):\n",
    "    is_greater = tf.greater(x, 0)\n",
    "    as_float = tf.dtypes.cast(is_greater, tf.float32)\n",
    "    doubled = tf.multiply(as_float, 2)\n",
    "    return tf.subtract(doubled, 1)\n",
    "output = step(tf.matmul(train_in, w))\n",
    "error = tf.subtract(train_out, output)\n",
    "mse = tf.reduce_mean(tf.square(error))\n",
    "delta = tf.matmul(train_in, error, transpose_a=True)\n",
    "train = tf.compat.v1.assign(w, tf.add(w, delta))\n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "err, target = 1.0, 0.0\n",
    "epoch, max_epochs = 0, 10\n",
    "while err > target and epoch < max_epochs:\n",
    "    epoch += 1\n",
    "    err, _ = sess.run([mse, train])\n",
    "    print('epoch:', epoch, 'mse:', err, 'output:', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.concatenate((np.ones(1).T,np.array((2,3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 0.8, 1.2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(k,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
